name: E2E Tests

on:
  push:
    branches: [main, develop, 'claude/**', 'worker*/**']
  pull_request:
    branches: [main, develop]
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  NODE_VERSION: '20'
  PNPM_VERSION: '8'

jobs:
  e2e-tests:
    name: E2E Tests - ${{ matrix.browser }}
    runs-on: ubuntu-latest
    timeout-minutes: 15

    strategy:
      fail-fast: false
      matrix:
        browser: [chromium, firefox, webkit]
        shard: [1, 2]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Install Playwright Browsers
        run: |
          cd apps/corp-cockpit-astro
          pnpm exec playwright install --with-deps ${{ matrix.browser }}

      - name: Build application
        run: |
          cd apps/corp-cockpit-astro
          pnpm build

      - name: Run E2E tests
        run: |
          cd apps/corp-cockpit-astro
          pnpm exec playwright test --project=${{ matrix.browser }} --shard=${{ matrix.shard }}/2
        env:
          CI: true
          BASE_URL: http://localhost:4321

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report-${{ matrix.browser }}-shard-${{ matrix.shard }}
          path: apps/corp-cockpit-astro/playwright-report/
          retention-days: 7

      - name: Upload test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.browser }}-shard-${{ matrix.shard }}
          path: apps/corp-cockpit-astro/test-results/
          retention-days: 7

      - name: Upload video recordings
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: test-videos-${{ matrix.browser }}-shard-${{ matrix.shard }}
          path: apps/corp-cockpit-astro/test-results/**/video.webm
          retention-days: 7

  e2e-mobile:
    name: E2E Tests - Mobile
    runs-on: ubuntu-latest
    timeout-minutes: 10

    strategy:
      fail-fast: false
      matrix:
        device: [mobile-chrome, mobile-safari, tablet]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Install Playwright Browsers
        run: |
          cd apps/corp-cockpit-astro
          pnpm exec playwright install --with-deps chromium webkit

      - name: Build application
        run: |
          cd apps/corp-cockpit-astro
          pnpm build

      - name: Run mobile E2E tests
        run: |
          cd apps/corp-cockpit-astro
          pnpm exec playwright test --project=${{ matrix.device }}
        env:
          CI: true
          BASE_URL: http://localhost:4321

      - name: Upload mobile test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report-${{ matrix.device }}
          path: apps/corp-cockpit-astro/playwright-report/
          retention-days: 7

  visual-regression:
    name: Visual Regression Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15

    env:
      # Strict visual regression thresholds
      MAX_DIFF_PERCENTAGE: 0.2
      MAX_DIFF_PIXELS: 100

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Install Playwright Browsers
        run: |
          cd apps/corp-cockpit-astro
          pnpm exec playwright install --with-deps chromium

      - name: Build application
        run: |
          cd apps/corp-cockpit-astro
          pnpm build

      - name: Run visual regression tests
        id: visual_tests
        run: |
          cd apps/corp-cockpit-astro
          pnpm exec playwright test tests/e2e/visual.spec.ts --project=chromium --reporter=json --output=test-results/visual-results.json
        continue-on-error: true
        env:
          CI: true
          BASE_URL: http://localhost:4321

      - name: Parse visual regression results
        id: parse_visual
        if: always()
        run: |
          cd apps/corp-cockpit-astro

          # Check if test results exist
          if [ ! -f "test-results/visual-results.json" ] && [ ! -f "playwright-report/results.json" ]; then
            echo "âš ï¸  No visual regression results found"
            echo "status=error" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Use whichever results file exists
          RESULTS_FILE="playwright-report/results.json"
          if [ -f "test-results/visual-results.json" ]; then
            RESULTS_FILE="test-results/visual-results.json"
          fi

          # Parse results and count visual diff failures
          node -e "
          const fs = require('fs');
          const path = require('path');

          const results = JSON.parse(fs.readFileSync('$RESULTS_FILE', 'utf8'));

          let totalTests = 0;
          let passedTests = 0;
          let failedTests = 0;
          let visualDiffs = [];

          // Parse test results
          results.suites?.forEach(suite => {
            suite.specs?.forEach(spec => {
              spec.tests?.forEach(test => {
                totalTests++;
                const testResult = test.results?.[0];

                if (testResult?.status === 'passed') {
                  passedTests++;
                } else if (testResult?.status === 'failed') {
                  failedTests++;

                  // Check for screenshot diffs
                  const attachments = testResult?.attachments || [];
                  const hasDiff = attachments.some(a =>
                    a.name?.includes('diff') || a.name?.includes('actual') || a.name?.includes('expected')
                  );

                  if (hasDiff) {
                    visualDiffs.push({
                      test: spec.title,
                      file: spec.file,
                      error: testResult.error?.message?.substring(0, 200) || 'Visual regression detected'
                    });
                  }
                }
              });
            });
          });

          // Generate summary
          const summary = {
            total: totalTests,
            passed: passedTests,
            failed: failedTests,
            visualDiffs: visualDiffs.length,
            diffs: visualDiffs.slice(0, 10), // Limit for output
            timestamp: new Date().toISOString()
          };

          fs.writeFileSync('visual-regression-summary.json', JSON.stringify(summary, null, 2));

          console.log('ðŸ“Š Visual Regression Test Summary:');
          console.log('Total tests:', totalTests);
          console.log('Passed:', passedTests);
          console.log('Failed:', failedTests);
          console.log('Visual diffs detected:', visualDiffs.length);

          // Set outputs
          console.log('::set-output name=total::' + totalTests);
          console.log('::set-output name=passed::' + passedTests);
          console.log('::set-output name=failed::' + failedTests);
          console.log('::set-output name=visual_diffs::' + visualDiffs.length);

          if (failedTests > 0) {
            console.log('âŒ Visual regression tests failed');
            process.exit(1);
          }

          console.log('âœ… All visual regression tests passed');
          "

      - name: Generate visual regression report
        if: always()
        run: |
          cd apps/corp-cockpit-astro

          cat > visual-regression-report.md << 'EOF'
          # ðŸ“¸ Visual Regression Test Report

          ## Summary

          **Date:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")
          **Branch:** ${{ github.ref_name }}
          **Commit:** ${{ github.sha }}

          EOF

          if [ -f "visual-regression-summary.json" ]; then
            node -e "
            const fs = require('fs');
            const summary = JSON.parse(fs.readFileSync('visual-regression-summary.json', 'utf8'));

            console.log('| Metric | Count | Status |');
            console.log('|--------|-------|--------|');
            console.log('| Total Tests | ' + summary.total + ' | â„¹ï¸ |');
            console.log('| Passed | ' + summary.passed + ' | ' + (summary.passed === summary.total ? 'âœ…' : 'â„¹ï¸') + ' |');
            console.log('| Failed | ' + summary.failed + ' | ' + (summary.failed === 0 ? 'âœ…' : 'âŒ') + ' |');
            console.log('| Visual Diffs | ' + summary.visualDiffs + ' | ' + (summary.visualDiffs === 0 ? 'âœ…' : 'âŒ') + ' |');
            console.log('');

            if (summary.visualDiffs > 0) {
              console.log('### Visual Differences Detected');
              console.log('');
              summary.diffs.forEach((diff, i) => {
                console.log(\`\${i + 1}. **\${diff.test}**\`);
                console.log(\`   - File: \${diff.file}\`);
                console.log(\`   - Error: \${diff.error}\`);
                console.log('');
              });
            }

            console.log('### Thresholds');
            console.log('');
            console.log('- **Max Diff Percentage:** ${{ env.MAX_DIFF_PERCENTAGE }}%');
            console.log('- **Max Diff Pixels:** ${{ env.MAX_DIFF_PIXELS }}');
            console.log('');
            console.log('**Overall Status:** ' + (summary.failed === 0 ? 'âœ… PASSED' : 'âŒ FAILED'));
            " >> visual-regression-report.md
          else
            echo "âš ï¸  No visual regression results available" >> visual-regression-report.md
          fi

          echo "" >> visual-regression-report.md
          echo "## ðŸ“‹ Next Steps" >> visual-regression-report.md
          echo "" >> visual-regression-report.md

          if [ -f "visual-regression-summary.json" ]; then
            FAILED=$(cat visual-regression-summary.json | grep -o '"failed":[0-9]*' | cut -d: -f2)
            if [ "$FAILED" -gt 0 ]; then
              echo "1. Review the diff images in the artifacts" >> visual-regression-report.md
              echo "2. If changes are intentional, update baselines: \`gh workflow run e2e.yml --ref ${{ github.ref_name }}\`" >> visual-regression-report.md
              echo "3. If changes are unintentional, fix the UI issues" >> visual-regression-report.md
            else
              echo "âœ… All visual regression tests passed - no action needed" >> visual-regression-report.md
            fi
          fi

          cat visual-regression-report.md

      - name: Upload visual regression report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: visual-regression-report
          path: apps/corp-cockpit-astro/visual-regression-report.md
          retention-days: 30

      - name: Upload visual test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: visual-regression-test-results
          path: apps/corp-cockpit-astro/playwright-report/
          retention-days: 30

      - name: Upload visual diff images
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: visual-diff-images
          path: |
            apps/corp-cockpit-astro/test-results/**/*-diff.png
            apps/corp-cockpit-astro/test-results/**/*-actual.png
            apps/corp-cockpit-astro/test-results/**/*-expected.png
          retention-days: 30

      - name: Upload all visual snapshots
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: visual-snapshots-all
          path: apps/corp-cockpit-astro/test-results/
          retention-days: 30

      - name: Comment PR with visual regression results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');

            let reportContent = '## ðŸ“¸ Visual Regression Test Results\n\n';

            try {
              const reportPath = path.join(process.env.GITHUB_WORKSPACE, 'apps/corp-cockpit-astro/visual-regression-report.md');
              if (fs.existsSync(reportPath)) {
                reportContent = fs.readFileSync(reportPath, 'utf8');
              }
            } catch (error) {
              reportContent += 'âš ï¸  Could not read visual regression report\n\n';
            }

            const status = '${{ steps.parse_visual.outcome }}' === 'success' ? 'âœ… PASSED' : 'âŒ FAILED';

            const comment = `${reportContent}

            ---

            **Overall Status:** ${status}

            **Workflow Run:** [View Details](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})

            ### ðŸ“¦ Artifacts

            - Visual Regression Report
            - Playwright Test Results
            ${status === 'âŒ FAILED' ? '- Visual Diff Images (actual vs expected)\n            - Complete Snapshots' : ''}

            ### ðŸ› ï¸ Update Baselines

            If the visual changes are intentional, update the baseline snapshots:

            \`\`\`bash
            # Run tests and update snapshots
            cd apps/corp-cockpit-astro
            pnpm exec playwright test tests/e2e/visual.spec.ts --update-snapshots

            # Or use workflow dispatch to update in CI
            gh workflow run e2e.yml
            \`\`\`

            ### ðŸ“š Resources

            - [Playwright Visual Comparisons](https://playwright.dev/docs/test-snapshots)
            - [Visual Testing Best Practices](https://playwright.dev/docs/best-practices#visual-comparisons)
            `;

            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const existingComment = comments.find(c => c.body?.includes('ðŸ“¸ Visual Regression Test Results'));

            if (existingComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingComment.id,
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }

      - name: Fail if visual regressions detected
        if: steps.parse_visual.outcome == 'failure'
        run: |
          echo "âŒ Visual regression tests failed - UI changes detected"
          echo "Review the diff images in artifacts to verify if changes are intentional"
          exit 1

  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Install Playwright Browsers
        run: |
          cd apps/corp-cockpit-astro
          pnpm exec playwright install --with-deps chromium

      - name: Build application
        run: |
          cd apps/corp-cockpit-astro
          pnpm build

      - name: Run performance tests
        run: |
          cd apps/corp-cockpit-astro
          pnpm exec playwright test tests/e2e/performance.spec.ts --project=chromium
        env:
          CI: true
          BASE_URL: http://localhost:4321

      - name: Upload performance results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-report
          path: apps/corp-cockpit-astro/playwright-report/
          retention-days: 30

  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Install Playwright Browsers
        run: |
          cd apps/corp-cockpit-astro
          pnpm exec playwright install --with-deps chromium

      - name: Build application
        run: |
          cd apps/corp-cockpit-astro
          pnpm build

      - name: Run security tests
        run: |
          cd apps/corp-cockpit-astro
          pnpm exec playwright test tests/e2e/security.spec.ts --project=chromium
        env:
          CI: true
          BASE_URL: http://localhost:4321

      - name: Upload security test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-test-report
          path: apps/corp-cockpit-astro/playwright-report/
          retention-days: 30

  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs:
      - e2e-tests
      - e2e-mobile
      - visual-regression
      - performance-tests
      - security-tests
    if: always()

    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts

      - name: Generate test summary
        run: |
          echo "# E2E Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- E2E Tests (Desktop): ${{ needs.e2e-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- E2E Tests (Mobile): ${{ needs.e2e-mobile.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Visual Regression: ${{ needs.visual-regression.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Performance Tests: ${{ needs.performance-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Security Tests: ${{ needs.security-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Test reports and artifacts are available in the Actions artifacts section." >> $GITHUB_STEP_SUMMARY

      - name: Check if all tests passed
        run: |
          if [[ "${{ needs.e2e-tests.result }}" != "success" ]]; then
            echo "::error::Desktop E2E tests failed"
            exit 1
          fi

          if [[ "${{ needs.e2e-mobile.result }}" != "success" ]]; then
            echo "::warning::Mobile E2E tests failed or were skipped"
          fi

          if [[ "${{ needs.visual-regression.result }}" != "success" ]]; then
            echo "::warning::Visual regression tests failed or were skipped"
          fi

          if [[ "${{ needs.performance-tests.result }}" != "success" ]]; then
            echo "::warning::Performance tests failed or were skipped"
          fi

          if [[ "${{ needs.security-tests.result }}" != "success" ]]; then
            echo "::error::Security tests failed"
            exit 1
          fi

          echo "âœ… All critical E2E tests passed"

  # Separate job for updating test baselines (manual trigger only)
  update-snapshots:
    name: Update Visual Snapshots
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Install Playwright Browsers
        run: |
          cd apps/corp-cockpit-astro
          pnpm exec playwright install --with-deps

      - name: Update snapshots
        run: |
          cd apps/corp-cockpit-astro
          pnpm exec playwright test tests/e2e/visual.spec.ts --update-snapshots

      - name: Upload updated snapshots
        uses: actions/upload-artifact@v4
        with:
          name: updated-snapshots
          path: apps/corp-cockpit-astro/tests/e2e/**/*.png
          retention-days: 30
