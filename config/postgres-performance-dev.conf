# ============================================================================
# PostgreSQL Performance Configuration for High-End Development Workstation
# Hardware: AMD Ryzen 9 9950X (16c/32t), 128GB DDR5 RAM, NVMe SSD
# ============================================================================
# Optimized for: Maximum performance, analytics workloads, parallel queries
# ============================================================================

# ------------------------------------------------------------------------------
# MEMORY SETTINGS (Optimized for 128GB RAM)
# ------------------------------------------------------------------------------

# Shared buffers: 25% of RAM (32GB for 128GB system)
shared_buffers = 32GB

# Effective cache size: 75% of RAM (96GB)
# Tells planner how much memory is available for caching
effective_cache_size = 96GB

# Work memory: Per-operation memory (sorts, hash joins)
# Increased for complex analytics queries
work_mem = 256MB  # Default: 4MB (64x increase for analytics)

# Maintenance work memory: For VACUUM, CREATE INDEX, etc.
maintenance_work_mem = 4GB  # Default: 64MB (64x increase)

# ------------------------------------------------------------------------------
# PARALLEL QUERY EXECUTION (Leverage 16 cores / 32 threads)
# ------------------------------------------------------------------------------

# Maximum parallel workers per gather operation
max_parallel_workers_per_gather = 8  # Use 8 cores per query

# Total parallel workers across all queries
max_parallel_workers = 16  # Use 16 cores total

# Background worker processes
max_worker_processes = 16

# Enable parallel operations
enable_parallel_hash = on
enable_partitionwise_aggregate = on
enable_partitionwise_join = on

# ------------------------------------------------------------------------------
# CONNECTION SETTINGS
# ------------------------------------------------------------------------------

# Maximum connections (increased for microservices + connection pool)
max_connections = 500  # Default: 100

# Reserved connections for superuser
superuser_reserved_connections = 5

# ------------------------------------------------------------------------------
# QUERY PLANNER OPTIMIZATION
# ------------------------------------------------------------------------------

# Statistics target (higher = better plans, slower ANALYZE)
default_statistics_target = 200  # Default: 100 (2x for analytics)

# Random page cost (lower for NVMe SSD)
random_page_cost = 1.1  # Default: 4.0 (SSD optimized)

# Effective I/O concurrency (NVMe can handle many concurrent I/O)
effective_io_concurrency = 200  # Default: 1 (200x for NVMe)

# ------------------------------------------------------------------------------
# JIT COMPILATION (Just-In-Time for complex queries)
# ------------------------------------------------------------------------------

jit = on
jit_above_cost = 100000  # JIT for queries costing > 100k
jit_inline_above_cost = 500000
jit_optimize_above_cost = 500000

# ------------------------------------------------------------------------------
# WAL (Write-Ahead Log) SETTINGS
# ------------------------------------------------------------------------------

# WAL buffers (increased for high-write workloads)
wal_buffers = 64MB  # Default: -1 (auto, typically 3% of shared_buffers)

# Checkpoint settings
checkpoint_timeout = 15min  # Default: 5min (less frequent checkpoints)
checkpoint_completion_target = 0.9  # Spread checkpoint I/O over time

# WAL size (increased for high-write workloads)
max_wal_size = 16GB  # Default: 1GB (16x increase)
min_wal_size = 4GB   # Default: 80MB

# ------------------------------------------------------------------------------
# AUTOVACUUM TUNING
# ------------------------------------------------------------------------------

# More aggressive autovacuum for high-write tables
autovacuum_max_workers = 6  # Default: 3 (2x for parallel vacuum)
autovacuum_naptime = 15s    # Default: 1min (more frequent)

# Vacuum thresholds (more aggressive)
autovacuum_vacuum_scale_factor = 0.02    # Default: 0.2 (trigger at 2% dead tuples)
autovacuum_analyze_scale_factor = 0.01   # Default: 0.1 (analyze at 1% changes)

# Vacuum cost (more aggressive)
autovacuum_vacuum_cost_delay = 5ms   # Default: 20ms (faster vacuum)
autovacuum_vacuum_cost_limit = 4000  # Default: 200 (20x more aggressive)

# ------------------------------------------------------------------------------
# LOGGING & MONITORING
# ------------------------------------------------------------------------------

# Slow query logging
log_min_duration_statement = 500  # Log queries > 500ms (dev: lower threshold)

# Log line prefix
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '

# Log checkpoints
log_checkpoints = on

# Log connections/disconnections
log_connections = on
log_disconnections = on

# Log lock waits
log_lock_waits = on
deadlock_timeout = 1s

# Log temporary files (indicates work_mem too small)
log_temp_files = 0  # Log all temp files

# Log autovacuum
log_autovacuum_min_duration = 0  # Log all autovacuum operations

# ------------------------------------------------------------------------------
# pg_stat_statements EXTENSION
# ------------------------------------------------------------------------------

# Enable pg_stat_statements (requires restart)
shared_preload_libraries = 'pg_stat_statements'

# Track more queries
pg_stat_statements.max = 20000  # Default: 5000 (track 20k queries)
pg_stat_statements.track = all
pg_stat_statements.track_utility = on
pg_stat_statements.track_planning = on

# ------------------------------------------------------------------------------
# STATISTICS & TRACKING
# ------------------------------------------------------------------------------

# Track query execution
track_activities = on
track_counts = on
track_io_timing = on  # Track I/O timing (slight overhead, worth it)
track_functions = all

# Statistics temp directory (use tmpfs for speed)
stats_temp_directory = '/var/run/postgresql'

# ------------------------------------------------------------------------------
# NOTES
# ------------------------------------------------------------------------------
#
# This configuration is optimized for:
# - 128GB RAM workstation
# - 16 cores / 32 threads CPU
# - NVMe SSD storage
# - Analytics/OLAP workloads (heavy aggregations, JOINs)
#
# Key optimizations:
# - 32GB shared_buffers (25% of RAM)
# - 96GB effective_cache_size (75% of RAM)
# - 256MB work_mem (for complex sorts/hash joins)
# - 8 parallel workers per query (leverage multi-core)
# - 500 max connections (for microservices)
# - Aggressive autovacuum (keep tables clean)
# - JIT compilation enabled (faster complex queries)
#
# To apply these settings:
# 1. Copy this file to Docker volume or mount as config
# 2. Restart PostgreSQL container
# 3. Verify settings: SELECT name, setting FROM pg_settings WHERE name IN ('shared_buffers', 'effective_cache_size', 'max_parallel_workers');
#
# ==============================================================================




