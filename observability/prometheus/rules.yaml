# TEEI CSR Platform - Prometheus Alerting Rules
# Ref: MULTI_AGENT_PLAN.md ยง D4.6 Observability Engineer

apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-rules
  namespace: monitoring
  labels:
    app: prometheus
    component: rules
data:
  teei-alerts.yaml: |
    groups:
    - name: teei_service_alerts
      interval: 30s
      rules:
      # High error rate alert
      - alert: HighErrorRate
        expr: |
          (
            sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
            /
            sum(rate(http_requests_total[5m])) by (service)
          ) > 0.05
        for: 5m
        labels:
          severity: warning
          component: "{{ $labels.service }}"
        annotations:
          summary: "High error rate on {{ $labels.service }}"
          description: "{{ $labels.service }} has an error rate of {{ $value | humanizePercentage }} (threshold: 5%)"

      # Critical error rate alert
      - alert: CriticalErrorRate
        expr: |
          (
            sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
            /
            sum(rate(http_requests_total[5m])) by (service)
          ) > 0.20
        for: 2m
        labels:
          severity: critical
          component: "{{ $labels.service }}"
        annotations:
          summary: "CRITICAL: Very high error rate on {{ $labels.service }}"
          description: "{{ $labels.service }} has an error rate of {{ $value | humanizePercentage }} (threshold: 20%)"

      # High latency alert
      - alert: HighLatency
        expr: |
          histogram_quantile(0.95,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
          ) > 2
        for: 10m
        labels:
          severity: warning
          component: "{{ $labels.service }}"
        annotations:
          summary: "High latency on {{ $labels.service }}"
          description: "{{ $labels.service }} p95 latency is {{ $value }}s (threshold: 2s)"

      # Service down alert
      - alert: ServiceDown
        expr: up{job=~"teei-.*"} == 0
        for: 2m
        labels:
          severity: critical
          component: "{{ $labels.job }}"
        annotations:
          summary: "Service {{ $labels.job }} is down"
          description: "Service {{ $labels.job }} has been down for more than 2 minutes"

      # Pod crash looping
      - alert: PodCrashLooping
        expr: rate(kube_pod_container_status_restarts_total{namespace="teei-production"}[15m]) > 0
        for: 5m
        labels:
          severity: warning
          component: "{{ $labels.pod }}"
        annotations:
          summary: "Pod {{ $labels.pod }} is crash looping"
          description: "Pod {{ $labels.pod }} has restarted {{ $value }} times in the last 15 minutes"

      # High memory usage
      - alert: HighMemoryUsage
        expr: |
          (
            container_memory_usage_bytes{namespace="teei-production"}
            /
            container_spec_memory_limit_bytes{namespace="teei-production"}
          ) > 0.90
        for: 5m
        labels:
          severity: warning
          component: "{{ $labels.pod }}"
        annotations:
          summary: "High memory usage on {{ $labels.pod }}"
          description: "{{ $labels.pod }} is using {{ $value | humanizePercentage }} of its memory limit"

      # High CPU usage
      - alert: HighCPUUsage
        expr: |
          (
            sum(rate(container_cpu_usage_seconds_total{namespace="teei-production"}[5m])) by (pod)
            /
            sum(container_spec_cpu_quota{namespace="teei-production"}/container_spec_cpu_period{namespace="teei-production"}) by (pod)
          ) > 0.90
        for: 10m
        labels:
          severity: warning
          component: "{{ $labels.pod }}"
        annotations:
          summary: "High CPU usage on {{ $labels.pod }}"
          description: "{{ $labels.pod }} is using {{ $value | humanizePercentage }} of its CPU limit"

      # Disk space low
      - alert: DiskSpaceLow
        expr: |
          (
            node_filesystem_avail_bytes{mountpoint="/"}
            /
            node_filesystem_size_bytes{mountpoint="/"}
          ) < 0.10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Low disk space on {{ $labels.instance }}"
          description: "{{ $labels.instance }} has less than 10% disk space available"

    - name: teei_database_alerts
      interval: 30s
      rules:
      # Database connection pool exhausted
      - alert: DatabasePoolExhausted
        expr: |
          (
            pg_stat_database_numbackends
            /
            pg_settings_max_connections
          ) > 0.80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Database connection pool nearly exhausted"
          description: "Database is using {{ $value | humanizePercentage }} of available connections"

      # Slow queries
      - alert: SlowDatabaseQueries
        expr: |
          rate(pg_stat_statements_mean_time_seconds[5m]) > 1
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Slow database queries detected"
          description: "Average query time is {{ $value }}s (threshold: 1s)"

    - name: teei_nats_alerts
      interval: 30s
      rules:
      # NATS consumer lag
      - alert: NATSConsumerLag
        expr: |
          nats_consumer_num_pending > 10000
        for: 10m
        labels:
          severity: warning
          component: "{{ $labels.consumer }}"
        annotations:
          summary: "High NATS consumer lag"
          description: "Consumer {{ $labels.consumer }} has {{ $value }} pending messages"

      # NATS slow consumers
      - alert: NATSSlowConsumer
        expr: |
          rate(nats_consumer_delivered_consumer_seq[5m]) == 0 and nats_consumer_num_pending > 0
        for: 5m
        labels:
          severity: critical
          component: "{{ $labels.consumer }}"
        annotations:
          summary: "NATS consumer is stuck"
          description: "Consumer {{ $labels.consumer }} is not processing messages"
