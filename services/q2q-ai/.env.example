# Q2Q AI Service Configuration

# ============================================================================
# AI Provider Selection
# ============================================================================
# Choose your default AI provider: claude, openai, or gemini
Q2Q_PROVIDER=claude

# ============================================================================
# API Keys (at least one required)
# ============================================================================
# Anthropic Claude API Key
# Get your key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-api03-...

# OpenAI API Key
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-...

# Google AI API Key (for Gemini)
# Get your key from: https://makersuite.google.com/app/apikey
GOOGLE_AI_API_KEY=...

# ============================================================================
# Model Configuration (optional - defaults provided)
# ============================================================================
# Claude Model Options:
#   - claude-3-5-sonnet-20241022 (default, best quality)
#   - claude-3-5-haiku-20241022 (faster, cheaper)
#   - claude-3-opus-20240229 (highest quality, most expensive)
Q2Q_CLAUDE_MODEL=claude-3-5-sonnet-20241022

# OpenAI Model Options:
#   - gpt-4o-mini (default, good balance)
#   - gpt-4o (higher quality)
#   - gpt-4-turbo (legacy)
#   - gpt-3.5-turbo (cheapest)
Q2Q_OPENAI_MODEL=gpt-4o-mini

# Gemini Model Options:
#   - gemini-1.5-flash (default, fast and cheap)
#   - gemini-1.5-pro (higher quality)
#   - gemini-2.0-flash-exp (experimental, free during preview)
Q2Q_GEMINI_MODEL=gemini-1.5-flash

# Maximum tokens for model output
Q2Q_MAX_TOKENS=4096

# Temperature (0.0 = deterministic, 1.0 = creative)
# Recommendation: Keep at 0.0 for consistent classification
Q2Q_TEMPERATURE=0.0

# ============================================================================
# Service Configuration
# ============================================================================
# Port for Q2Q AI service
PORT_Q2Q_AI=3005

# Database connection (from shared-schema)
DATABASE_URL=postgresql://user:password@localhost:5432/teei_csr

# ============================================================================
# Performance Tuning (optional)
# ============================================================================
# Retry configuration
# Q2Q_RETRY_MAX_ATTEMPTS=3
# Q2Q_RETRY_INITIAL_DELAY_MS=1000
# Q2Q_RETRY_MAX_DELAY_MS=10000
# Q2Q_RETRY_BACKOFF_MULTIPLIER=2

# Evaluation batch size (for calibration runs)
# Q2Q_EVAL_BATCH_SIZE=10

# ============================================================================
# Development / Testing
# ============================================================================
# Set to 'true' to enable debug logging
# DEBUG=true

# Mock AI responses for testing (bypasses real API calls)
# Q2Q_MOCK_MODE=false
